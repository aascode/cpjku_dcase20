{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,json,os,importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained models from https://zenodo.org/record/4282667 and extract the models directories into the \"pretrained_models\" directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub1', 'README.md', 'sub3', 'ensem2', 'sub2', 'ensem3', 'ensem1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"pretrained_models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the pretrained model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"pretrained_models/sub1/\"\n",
    "model_path=\"pretrained_models/sub2/\"\n",
    "#model_path=\"pretrained_models/sub3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model specified by model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset_config.json',\n",
       " 'eval_predictions_probs.pth',\n",
       " 'description.txt',\n",
       " 'eval_predictions.csv',\n",
       " 'model_from_training_state_dict.pth',\n",
       " 'model_config.json',\n",
       " 'model_state_dict.pth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model config from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path+'model_config.json',\"r\")as f:\n",
    "    model_config=json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n_blocks_per_stage is specified ignoring the depth param, nc=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decomposed Conv2d with decomp_factor of  4 \n",
      "\n",
      "\n",
      "WARNING: stage2 removed\n",
      "WARNING: stage3 removed\n"
     ]
    }
   ],
   "source": [
    "module = importlib.import_module('models.{}'.format(model_config['arch']))\n",
    "Network = getattr(module, 'Network')\n",
    "model=Network(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict=torch.load(model_path+\"/model_state_dict.pth\")\n",
    "#state_dict=torch.load(model_path+\"/model_from_training_state_dict.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0332, -0.0353, -0.0135, -0.0505, -0.0453],\n",
       "          [-0.0552, -0.0347,  0.0185, -0.0019, -0.0548],\n",
       "          [-0.0089,  0.0357,  0.0280,  0.0047,  0.0296],\n",
       "          [ 0.0402,  0.0489, -0.0048, -0.0035, -0.0084],\n",
       "          [-0.0181,  0.0472,  0.0243, -0.0381,  0.1149]],\n",
       "\n",
       "         [[ 0.0471,  0.1449,  0.0569,  0.1116,  0.0880],\n",
       "          [-0.0413, -0.1156, -0.0679, -0.0853, -0.1174],\n",
       "          [-0.0305, -0.0082, -0.0980, -0.0265,  0.0358],\n",
       "          [-0.0673, -0.0496,  0.0275,  0.0101, -0.0198],\n",
       "          [-0.0550, -0.0758, -0.0014,  0.0543,  0.0133]]],\n",
       "\n",
       "\n",
       "        [[[-0.0581, -0.0017,  0.0217, -0.0299, -0.0004],\n",
       "          [-0.0473,  0.0263,  0.0417,  0.0317,  0.0562],\n",
       "          [-0.0889, -0.0444, -0.0570, -0.0151, -0.0479],\n",
       "          [ 0.0270,  0.0557, -0.0411,  0.0242,  0.0256],\n",
       "          [-0.1002, -0.0568, -0.0278, -0.0842, -0.1010]],\n",
       "\n",
       "         [[-0.0611, -0.0424, -0.0272, -0.0378,  0.0148],\n",
       "          [ 0.0748,  0.0144,  0.0188,  0.1204,  0.1204],\n",
       "          [-0.0231, -0.0835,  0.0422,  0.0446,  0.0259],\n",
       "          [-0.0724, -0.0228, -0.0257,  0.0401,  0.0543],\n",
       "          [-0.0189, -0.0627,  0.0090, -0.0052, -0.0335]]],\n",
       "\n",
       "\n",
       "        [[[-0.0829, -0.0563, -0.0595, -0.0695, -0.0005],\n",
       "          [ 0.0534,  0.0753,  0.1628,  0.1427,  0.1254],\n",
       "          [-0.0351, -0.0566,  0.0656,  0.0317,  0.0485],\n",
       "          [-0.0360, -0.0380, -0.0014,  0.0032, -0.0398],\n",
       "          [-0.0194,  0.0670,  0.0853, -0.0539, -0.0543]],\n",
       "\n",
       "         [[-0.0296,  0.0691,  0.0638,  0.1112,  0.0463],\n",
       "          [-0.0080,  0.0040,  0.0040,  0.0555,  0.0499],\n",
       "          [ 0.0252, -0.0288,  0.0006, -0.0161, -0.0560],\n",
       "          [-0.0192,  0.0226, -0.0278, -0.0212, -0.0115],\n",
       "          [-0.0407, -0.0371, -0.0477,  0.0720,  0.0504]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0201, -0.0431, -0.0165,  0.0480, -0.0163],\n",
       "          [ 0.0043, -0.0668,  0.0749,  0.0850, -0.0495],\n",
       "          [ 0.0371,  0.0371,  0.0447,  0.0012,  0.0102],\n",
       "          [-0.0370,  0.0699, -0.0119, -0.0718, -0.0388],\n",
       "          [ 0.0093,  0.0526, -0.0145, -0.0758,  0.0124]],\n",
       "\n",
       "         [[ 0.0273, -0.0474, -0.0135,  0.0765,  0.0287],\n",
       "          [ 0.0352, -0.0624,  0.0838,  0.1630,  0.0240],\n",
       "          [ 0.0304, -0.0047, -0.0157,  0.0561,  0.0190],\n",
       "          [-0.0258,  0.0544,  0.0155, -0.0996, -0.0559],\n",
       "          [-0.0054,  0.0305, -0.0255, -0.0649, -0.0684]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0076,  0.0566,  0.0746,  0.0562,  0.0107],\n",
       "          [-0.0750,  0.0312,  0.1069, -0.0122,  0.0896],\n",
       "          [-0.0307, -0.0267, -0.1085, -0.0815, -0.0497],\n",
       "          [ 0.0404,  0.0038,  0.0137, -0.0518, -0.0497],\n",
       "          [ 0.0219,  0.0667,  0.0238,  0.0084,  0.0015]],\n",
       "\n",
       "         [[ 0.0024,  0.0100,  0.0057,  0.0361,  0.0081],\n",
       "          [-0.0596,  0.0038,  0.0320, -0.1011,  0.0751],\n",
       "          [-0.0447, -0.0790, -0.0463, -0.0886, -0.0242],\n",
       "          [-0.0251,  0.0066, -0.0824,  0.0050,  0.0228],\n",
       "          [-0.0190, -0.0023, -0.0044,  0.0424,  0.0260]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0332,  0.0673,  0.0455, -0.0175, -0.0563],\n",
       "          [ 0.0166, -0.0462, -0.0629, -0.0570, -0.0575],\n",
       "          [-0.0496, -0.0358,  0.0098,  0.0077,  0.0012],\n",
       "          [ 0.0935, -0.0456, -0.0460, -0.0542, -0.0115],\n",
       "          [ 0.0546,  0.1028, -0.0008,  0.0219,  0.0256]],\n",
       "\n",
       "         [[ 0.0301,  0.0171,  0.0178, -0.0322, -0.0381],\n",
       "          [-0.1099, -0.0635, -0.1151, -0.0388, -0.0742],\n",
       "          [ 0.0077, -0.0436, -0.0239, -0.0386, -0.1003],\n",
       "          [-0.0235,  0.0282,  0.0201, -0.0169, -0.0729],\n",
       "          [ 0.0818,  0.1032,  0.0739,  0.0420, -0.0178]]]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['in_c.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the weights are float16 cast the model\n",
    "if [v for k,v in state_dict.items()][0].dtype==torch.float16:\n",
    "    model=model.half()\n",
    "    print(\"model in float16\")\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_zero_params_nonbn(model):\n",
    "    sum_params = 0\n",
    "    sum_non_zero= 0 \n",
    "    desc=\"\"\n",
    "    def calc_params(model):\n",
    "        nonlocal desc, sum_params, sum_non_zero\n",
    "        skip=\"count\"\n",
    "        if \"batchnorm\" in  type(model).__name__.lower():\n",
    "            skip=\"skip\"\n",
    "        for k,p in model.named_parameters(recurse=False):\n",
    "            if p.requires_grad:\n",
    "                nonzero = (p != 0).sum()\n",
    "                total= p.numel()\n",
    "                desc += f\"type {type(model).__name__}, {k},  {total}, {nonzero}, {p.dtype}, {skip} \" + \"\\n\"\n",
    "                if skip!=\"skip\":\n",
    "                    sum_params+=total\n",
    "                    sum_non_zero+=nonzero\n",
    "    model.apply(calc_params)       \n",
    "    return desc,sum_params,sum_non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  17520 Non-Zero: tensor(17520, device='cuda:0')\n",
      "type Conv2d, weight,  2400, 2400, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  1296, 1296, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  144, 144, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  1296, 1296, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  1296, 1296, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  1296, 1296, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  144, 144, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  144, 144, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type Conv2d, weight,  144, 144, torch.float16, count \n",
      "type Conv2d, weight,  576, 576, torch.float16, count \n",
      "type BatchNorm2d, weight,  48, 48, torch.float16, skip \n",
      "type BatchNorm2d, bias,  48, 48, torch.float16, skip \n",
      "type Conv2d, weight,  144, 144, torch.float16, count \n",
      "type BatchNorm2d, weight,  3, 3, torch.float16, skip \n",
      "type BatchNorm2d, bias,  3, 3, torch.float16, skip \n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc,sum_params,sum_non_zero=count_non_zero_params_nonbn(model)\n",
    "print(\"Total: \",sum_params, \"Non-Zero:\",sum_non_zero)\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "# the eval json config dataset specifies that the norms should be calculated from all the training clips. \n",
    "with open('configs/datasets/dcase2020b_eval.json',\"r\")as f:\n",
    "    dataset_config=json.load(f)\n",
    "datasetm=datasets.DatasetsManager(dataset_config['audiodataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from 'd20t1b'\n",
      "normalizing dataset\n",
      "normalized train!\n",
      "attempting to load x from cache at datasets/cached_datasets/d20t1b/tr_mean_676d70_f1_apd18_stereo_obj.pt...\n",
      "loaded datasets/cached_datasets/d20t1b/tr_mean_676d70_f1_apd18_stereo_obj.pt from cache in 0.0007960796356201172 \n",
      "attempting to load x from cache at datasets/cached_datasets/d20t1b/tr_std_676d70_f1_apd18_stereo_obj.pt...\n",
      "loaded datasets/cached_datasets/d20t1b/tr_std_676d70_f1_apd18_stereo_obj.pt from cache in 0.00045108795166015625 \n",
      "normalized train!\n",
      "normalized test!\n",
      "normalized SUB dataset!\n",
      "loading dataset from 'd20t1b_sub'\n"
     ]
    }
   ],
   "source": [
    "trainds=datasetm.get_train_set()\n",
    "testds=datasetm.get_train_set()\n",
    "evalds=datasetm.get_sub_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dev train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([1, 2, 256, 431])\n",
      "in_c: torch.Size([1, 48, 127, 215])\n",
      "stage1: torch.Size([1, 48, 15, 26])\n",
      "stage2: torch.Size([1, 48, 15, 26])\n",
      "stage3: torch.Size([1, 48, 15, 26])\n",
      "feed_forward: torch.Size([1, 3, 1, 1])\n",
      "logit: torch.Size([1, 3])\n",
      "all  14400  correct  14268  ratio= 0.9908333333333333\n"
     ]
    }
   ],
   "source": [
    "all_y=0\n",
    "corr_y=0\n",
    "model.eval()\n",
    "model.cuda()\n",
    "half_mode=True\n",
    "data_loader = torch.utils.data.DataLoader(trainds,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for i,(x,idx,y) in enumerate(data_loader):\n",
    "        if i%10==0:\n",
    "            print(i,\"/\",len(data_loader),end=\"\\r\")\n",
    "        x=x.cuda()\n",
    "        if half_mode:\n",
    "            x=x.half()\n",
    "        out=model(x)\n",
    "        all_y+=1\n",
    "        corr_y+=(torch.argmax(out).cpu()==y).sum().item()\n",
    "print(\"all \", all_y,\" correct \",corr_y,\" ratio=\",corr_y*1./all_y) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all  8640  correct  0  ratio= 0.0\n"
     ]
    }
   ],
   "source": [
    "all_y=0\n",
    "corr_y=0\n",
    "model.eval()\n",
    "model.cuda()\n",
    "half_mode=True\n",
    "data_loader = torch.utils.data.DataLoader(evalds,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,num_workers=10)\n",
    "preds=[]\n",
    "file_names=[]\n",
    "with torch.no_grad():\n",
    "    for i,(x,idx,y) in enumerate(data_loader):\n",
    "        if i%10==0:\n",
    "            print(i,\"/\",len(data_loader),end=\"\\r\")\n",
    "        x=x.cuda()\n",
    "        if half_mode:\n",
    "            x=x.half()\n",
    "        out=model(x)\n",
    "        all_y+=1\n",
    "        file_names+=[a for a in idx]\n",
    "        preds+=[out.cpu()]\n",
    "print(\"all \", all_y,\" correct \",corr_y,\" ratio=\",corr_y*1./all_y) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfiles,pprobs=torch.load(model_path+\"eval_predictions_probs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfiles==file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching tensor(8640) out of  8640\n"
     ]
    }
   ],
   "source": [
    "print(\"matching\",(torch.argmax(pprobs.float(),1)== torch.argmax(torch.cat(preds,0).float(),1) ).sum(),\"out of \" ,pprobs.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
